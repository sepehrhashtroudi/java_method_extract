@Override	Token nextToken(Token tkn) throws IOException {	    int lastChar = in.readAgain();	    int c = in.read();	    boolean eol = isEndOfLine(c);	    c = in.readAgain();	    if (emptyLinesIgnored) {	        while (eol && (lastChar == '\n' || lastChar == '\r' || lastChar == ExtendedBufferedReader.UNDEFINED) && !isEndOfFile(lastChar)) {	            lastChar = c;	            c = in.read();	            eol = isEndOfLine(c);	            c = in.readAgain();	            if (isEndOfFile(c)) {	                tkn.type = EOF;	                return tkn;	            }	        }	    }	    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {	        tkn.type = EOF;	        return tkn;	    }	    while (tkn.type == INVALID) {	        if (surroundingSpacesIgnored) {	            while (isWhitespace(c) && !eol) {	                c = in.read();	                eol = isEndOfLine(c);	            }	        }	        if (isCommentStart(c)) {	            in.readLine();	            tkn = nextToken(tkn.reset());	        } else if (isDelimiter(c)) {	            tkn.type = TOKEN;	        } else if (eol) {	            tkn.type = EORECORD;	        } else if (isEncapsulator(c)) {	            encapsulatedTokenLexer(tkn, c);	        } else if (isEndOfFile(c)) {	            tkn.type = EOF;	            tkn.isReady = true;	        } else {	            simpleTokenLexer(tkn, c);	        }	    }	    return tkn;	}
private Token simpleTokenLexer(Token tkn, int c) throws IOException {	    while (true) {	        if (isEndOfLine(c)) {	            tkn.type = EORECORD;	            break;	        } else if (isEndOfFile(c)) {	            tkn.type = EOF;	            tkn.isReady = true;	            break;	        } else if (isDelimiter(c)) {	            tkn.type = TOKEN;	            break;	        } else if (isEscape(c)) {	            tkn.content.append((char) readEscape(c));	        } else {	            tkn.content.append((char) c);	        }	        c = in.read();	    }	    if (surroundingSpacesIgnored) {	        trimTrailingSpaces(tkn.content);	    }	    return tkn;	}
private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {	    int startLineNumber = getLineNumber();	    while (true) {	        c = in.read();	        if (isEscape(c)) {	            tkn.content.append((char) readEscape(c));	        } else if (isEncapsulator(c)) {	            if (isEncapsulator(in.lookAhead())) {	                c = in.read();	                tkn.content.append((char) c);	            } else {	                while (true) {	                    c = in.read();	                    if (isDelimiter(c)) {	                        tkn.type = TOKEN;	                        return tkn;	                    } else if (isEndOfFile(c)) {	                        tkn.type = EOF;	                        tkn.isReady = true;	                        return tkn;	                    } else if (isEndOfLine(c)) {	                        tkn.type = EORECORD;	                        return tkn;	                    } else if (!isWhitespace(c)) {	                        throw new IOException("(line " + getLineNumber() + ") invalid char between encapsulated token and delimiter");	                    }	                }	            }	        } else if (isEndOfFile(c)) {	            throw new IOException("(startline " + startLineNumber + ") EOF reached before encapsulated token finished");	        } else {	            tkn.content.append((char) c);	        }	    }	}
